{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "E-rn2TRzZBnG",
        "outputId": "bf7fd132-b1a5-4a8e-a7bb-585e4673bcf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Done/training/pa/pa.1.JPG'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-0ee42f847dd3>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done/training/pa/pa.1.JPG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Done/training/pa/pa.1.JPG'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/INDUNI/Done\")\n",
        "os.getcwd()\n",
        "\n",
        "\n",
        "\n",
        "img = image.load_img(\"training/pa/pa.1.JPG\")\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "\n",
        "\n",
        "\n",
        "cv2.imread(\"training/pa/pa.1.JPG\").shape\n",
        "\n",
        "\n",
        "train = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "\n",
        "validation = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "\n",
        "train_dataset = train.flow_from_directory('training/',\n",
        "                                          target_size = (200,200),\n",
        "                                          batch_size = 3,\n",
        "                                          class_mode = 'binary')\n",
        "\n",
        "\n",
        "validation_dataset = validation.flow_from_directory('validation/',\n",
        "                                                   target_size = (200,200),\n",
        "                                                   batch_size = 3,\n",
        "                                                   class_mode = 'binary')\n",
        "\n",
        "\n",
        "train_dataset.class_indices\n",
        "\n",
        "\n",
        "train_dataset.classes\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape = (200,200,3)),\n",
        "                                   # MaxPooling layer with pool size (2, 2)\n",
        "                                    tf.keras.layers.MaxPool2D(2,2),\n",
        "                                   # Convolutional layer with 32 filters, each of size (3, 3), and ReLU activation\n",
        "                                    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu'),\n",
        "                                    tf.keras.layers.MaxPool2D(2,2),\n",
        "                                   # Convolutional layer with 64 filters, each of size (3, 3), and ReLU activation\n",
        "                                    tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
        "                                    tf.keras.layers.MaxPool2D(2,2),\n",
        "                                   # Flatten layer to convert 3D feature maps to 1D feature vectors\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                   # Dense (fully connected) layer with 512 units and ReLU activation\n",
        "                                    tf.keras.layers.Dense(512,activation = 'relu'),\n",
        "                                   # Output layer with 1 unit and sigmoid activation for binary classification\n",
        "                                    tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
        "                                    ])\n",
        "\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = RMSprop(lr=0.001),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_fit = model.fit(train_dataset,\n",
        "                      steps_per_epoch = 5,\n",
        "                      epochs = 30,\n",
        "                      validation_data = validation_dataset)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "validation_dataset.class_indices\n",
        "\n",
        "\n",
        "dir_path = 'testing/'\n",
        "\n",
        "\n",
        "for i in os.listdir(dir_path):\n",
        "    # Load the image and resize it to the target size\n",
        "  img = image.load_img(dir_path+ i,target_size=(200,200))\n",
        "  # Display the image using matplotlib\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  # Convert the image to a NumPy array and add an extra dimension\n",
        "  X = image.img_to_array(img)\n",
        "  X = np.expand_dims(X,axis = 0)\n",
        "# Stack the array vertically to create a batch of images\n",
        "  images = np.vstack([X])\n",
        "# Make a prediction using the trained model\n",
        "  val = model.predict(images)\n",
        "# Check the predicted value and print the corresponding class label\n",
        "  if val == 0:\n",
        "    print(\"This is Letter 'pa' in Sinhala\")\n",
        "  else:\n",
        "    print(\"This is Letter 'ra' in Sinhala\")"
      ]
    }
  ]
}